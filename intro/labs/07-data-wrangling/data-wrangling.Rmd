---
title: "Data Wrangling"
author: "Andrew Bray (from the CRAN tutorial)"
output:
  ioslides_presentation:
    incremental: true
---

```{r echo = FALSE}
knitr::opts_chunk$set(warnings = FALSE, message = FALSE)
library(oilabs)
```

## Two paradigms

### R {.build}
```{r}
fdims <- bdims[bdims$sex == "f", ]
mean(fdims$hgt)
```

### R with dplyr
```{r}
library(dplyr)
fdims <- filter(bdims, sex == "f")
summarize(fdims, mean = mean(hgt))
```


## R Subsetting {.build}

```{r}
fdims <- bdims[bdims$sex == "f", ]
```

- Square brackets are used to subset dataframes.
- `[rows, columns]`


## R Summaries {.build}

```{r}
mean(fdims$hgt)
```

- Many commands operate on a *vector* (column) of data extracted from a dataframe
using the `$`.


## dplyr Subsetting {.build}

```{r}
fdims <- filter(bdims, sex == "f")
```

- `dplyr` contains separate functions to *filter* the rows and *select* the columns.

```{r}
fdims <- bdims %>% filter(sex == "f")
```

- Can also *chain* commands using the pipe.


## dplyr Summaries

```{r}
summarize(fdims, mean = mean(hgt))
```

- Any numerical summary that you want to apply to a column of a dataframe
is specified within `summarize()`.

```{r}
fdims %>% summarize(mean = mean(hgt))
```

- This, too, can be put into a chain.


## Why dplyr?

Data sets are often of high *volume* (lots of rows) and high *variety* (lots
of columns). This is overwhelming to visualize and analyze, so we find ourselves
chopping the data set up into more manageable and meaningful chunks. We also 
often need to perform operations to organize and clean our data.

This is all possible in base R, but with `dplyr`, it is **simple**, **readible**, 
and **fast**.


## The Seven Verbs (commands)

- filter
- arrange
- select
- distinct
- mutate
- summarise
- sample_n


## filter()

Allows you to select a subset of the **rows** of a data frame. The first
argument is the name of the data frame, the following arguments are the
filters that you'd like to apply

For all flights on January 1st:

```{r message = FALSE, warning = FALSE}
library(dplyr)
library(nycflights13)
filter(flights, month == 1, day == 1)
```


## Constructing filters

Filters are constructed of **logical operators**: `<`, `>`, `<=`, `>=`, `==`,
`!=` (and some others).

Adding them one by one to `filter()` is akin to saying "this AND that". To say
"this OR that OR both", use |.

```{r}
filter(flights, month == 1 | month == 2)
```


## Your turn

Construct filters to isolate:

1. Flights that left on St. Patrick's Day.
2. Flights that were destined for Chicago's primary airport.
3. Flights that were destined for Chicago's primary airport and were operated by
United Airlines.
4. Flights with flight times more than 2000 miles or that were in the air more
than 5 hours.


##

1. Flights that left on St. Patrick's Day.
2. Flights that were destined for Chicago's primary airport.
3. Flights that were destined for Chicago's primary airport and were operated by
United Airlines.
4. Flights with flight times more than 2000 miles or that were in the air more
than 5 hours.

```{r eval = FALSE}
filter(flights, month == 3, day == 17)
filter(flights, dest == "ORD")
filter(flights, dest == "ORD", carrier == "UA")
filter(flights, distance > 2000 | air_time > 5*60)
```


## arrange()

`arrange()` works similarly to `filter()` except that instead of filtering or 
selecting rows, it reorders them. It takes a data frame, and a set of column 
names (or more complicated expressions) to order by. If you provide more than 
one column name, each additional column will be used to break ties in the values
of preceding columns:

```{r, eval = FALSE}
arrange(flights, year, month, day)
```

Use `desc()` to sort in descending order.

```{r, eval = FALSE}
arrange(flights, desc(arr_delay))
```


## select()

Often you work with large datasets with many columns where only a few are 
actually of interest to you. `select()` allows you to rapidly zoom in on a useful
subset using operations that usually only work on numeric variable positions:

```{r eval=FALSE}
select(flights, year, month, day)
```

You can exclude columns using `-` and specify a range using `:`.

```{r eval = FALSE}
select(flights, -(year:day))
```


## distinct()

A common use of `select()` is to find out which values a set of variables takes. 
This is particularly useful in conjunction with the `distinct()` verb which only 
returns the unique values in a table.

What do the following data correspond to?

```{r}
distinct(select(flights, origin, dest))
```


## mutate()

As well as selecting from the set of existing columns, it's often useful to add 
new columns that are functions of existing columns. This is the job of `mutate()`:

```{r}
mutate(flights, gain = arr_delay - dep_delay)
```


## summarise() and sample_n()

`summarise()` collapses a data frame to a single row. It's not very useful yet. 
`sample_n()` provides you with a random sample of the rows.

```{r}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
sample_n(flights, 10)
```


## Your turn

**Mutate** the data into a new variable that contains the average speed traveled
by the plane for each flight. **Select** that new variable and save it, along with
tailnum, as a new dataframe object.


## Your turn

```{r}
flights2 <- mutate(flights, speed = distance/(air_time/60))
speed <- select(flights2, tailnum, speed)
```


## Aggregation aka group_by()

These verbs become really powerful when you combine them with the idea of 
"group by", repeating the operation individually on groups of observations 
within the dataset. The `group_by()` function describes how to break a 
dataset down into groups of rows.

You can then use the resulting object in exactly the same functions as above;
they'll automatically work "by group" when the input is a grouped.


## group_by()

We can find the fastest airplanes in the bunch:

```{r}
by_tailnum <- group_by(speed, tailnum)
avg_speed <- summarise(by_tailnum, 
                       count = n(), 
                       avg_speed = mean(speed, na.rm = TRUE))
arrange(avg_speed, desc(avg_speed))
```


## Chaining

Instead of applying each verb step-by-step, we can chain them into a single
data pipeline, connected with the `%>%` operator. You start the pipeline with
a dataframe and then pass it to each function in turn.

```{r}
speed %>%
  group_by(tailnum) %>% 
  summarise(count = n(), avg_speed = mean(speed, na.rm = TRUE)) %>%
  arrange(desc(avg_speed))
```


## Your turn

Form a chain that creates a data frame containing only carrier and their
mean departure delay time. Which carriers have the highest and lowest mean
delays?


## Your turn

```{r}
flights %>%
  group_by(carrier) %>%
  summarise(avg_delay = mean(dep_delay, na.rm = TRUE)) %>%
  arrange(desc(avg_delay))
```


## Your turn again

Say you're curious about the relationship between the number of flights each
plane made in 2013, the mean distance that each of those planes flew, and the
mean arrival delay. You also want to exclude the edge cases from your analysis,
so focus on the planes that have logged more than 20 flights and flown an average
distance of less than 2000 miles. Please form the chain that creates this dataset.


## Your turn again

```{r}
delay <- flights %>%
  group_by(tailnum) %>%
  summarise(count = n(),
            dist = mean(distance, na.rm = TRUE), 
            delay = mean(arr_delay, na.rm = TRUE)) %>%
  filter(count > 20, dist < 2000)
```
 
 
## Visualizing the data
 
```{r eval = TRUE, message = FALSE, warning = FALSE, echo = FALSE}
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
 geom_point(aes(size = count), alpha = 1/2) +
 geom_smooth() +
 scale_size_area()
```



